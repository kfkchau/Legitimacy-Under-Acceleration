# THE CITY WE’RE ACTUALLY GOVERNING: Rules, Routes, and the Governance–Economic System

We talk about AI governance as if it’s mostly about **rules**:  
principles, risk categories, impact assessments, controls, audits.

If you’re living **inside** a system – as a worker, a citizen, a founder, a policymaker – you experience something different:

- not just the rules on paper,  
- but the **routes** that are actually open to you.

That’s the gap *Legitimacy Under Acceleration* is interested in:  
not just the laws and frameworks, but the **city** they create.

---

## 1. Two halves of the same city

I work with a simple image: a city being rebuilt while people are still living in it.

### 1.1 The rule side: traffic system and institutions

One half of the city is built out of **rules**.

These are the traffic lights and signposts of social life:

- laws and regulations  
- policies and standards  
- procedures, guidelines and professional codes  
- unwritten norms that everyone “just knows”

Institutions are where these rule systems live and get operated:

- parliaments and ministries  
- regulators and courts  
- companies and boards  
- standards bodies and professional associations  
- universities, unions, industry groups

Together, they form an **ecosystem of governance mechanisms**:

- how rules are made,  
- how they’re interpreted,  
- how they’re enforced,  
- how they change,  
- and how they’re explained when people push back.

This is the part most AI governance frameworks focus on.

### 1.2 The value side: routes, routines, and what “counts”

The other half of the city is built out of **value**.

People constantly make judgements about what matters:

- which work deserves respect  
- which products are worth paying for  
- which careers feel meaningful  
- which futures are worth aiming at

In the city, this shows up as the **routes people actually drive**:

- the commutes and routines they stick to  
- the neighbourhoods they crowd  
- the shortcuts and detours they take  
- the areas they quietly avoid

Those everyday route choices stand in for **value signals**:  
all the ways the world tells us what is “worth it”:

- salaries and prices  
- promotions and titles  
- likes, rankings and invitations  
- informal status and reputation

Markets are where those judgements get **compressed** into numbers:  
prices, wages, KPIs, share prices.

The wider economy is the big **feedback loop** that:

- takes those signals,  
- feeds them back into people’s lives,  
- and nudges what feels possible or worthwhile next:
  - what gets funded,  
  - which jobs are attractive,  
  - what counts as success or failure.

Most of this never appears in a law or a framework.  
But it determines whether people experience the system as **liveable**.

---

## 2. The governance–economic system: rules + routes

Put those halves together and you get what I call the **governance–economic system**:

- the **rule layer** – how decisions are structured, constrained and contested  
- the **value layer** – how effort, contribution and risk are recognised and rewarded

You can’t really understand one without the other:

- rules that ignore value signals drift into irrelevance or provoke backlash  
- value signals without rule structure drift into exploitation or collapse

Historically, we’ve separated the study of these halves:

- public law, political theory and public administration on the **rule side**  
- economics, finance and management on the **value side**

Under AI acceleration, that split stops being tenable.

AI is reconfiguring **how rules are applied**  
*and* **what kinds of work and contribution “count”** at the same time.

---

## 3. How acceleration breaks the alignment

Acceleration isn’t just “faster innovation”. It’s:

- faster **information flow**  
- faster **coordination**  
- faster **feedback loops** – social, economic, political

That hits both halves of the city at once.

### 3.1 On the rule side

We see:

- constant demands for new rules and standards  
- more complex, layered obligations (UNESCO, OECD, NIST, EU, ISO, national law, sectoral codes)  
- institutions struggling to keep up with:
  - new models  
  - new use-cases  
  - new kinds of harm and failure

Most of the global governance stack is still:

- **paper-first** – PDF principles and guidelines  
- **model-centric** – thinking in terms of “systems” and “providers”, not actual workflows  
- **slow to metabolise** – weak mechanisms for:
  - retiring bad rules,  
  - reconciling contradictions,  
  - reacting coherently to new evidence

So we get traffic lights that change late, or not at all.

### 3.2 On the value side

At the same time, AI and automation are reshaping:

- which tasks humans still do  
- which skills are rewarded  
- which roles are structurally fragile

People use their work to answer questions like:

- “What am I actually good at?”  
- “What do people rely on me for?”  
- “What kind of life am I building here?”

When AI moves into the parts of work people were proud of:

- writing, analysing, diagnosing, designing, coordinating –  
the visible **routes** through the city change:

- some career paths thin out or disappear  
- others become overcrowded and precarious  
- new paths emerge that aren’t yet recognised or rewarded

The risk is simple:

> Even if the traffic system is “safe and compliant”,  
> people can feel like there are fewer meaningful journeys left for them to make.

That’s how legitimacy leaks out.

---

## 4. Why AI governance can’t stay rule-only

Most current AI governance efforts sit almost entirely on the **rule side**:

- principles, obligations, risk classes  
- impact assessments and audits  
- definitions of high-risk vs low-risk systems

That’s necessary. It’s not sufficient.

Three things follow if you take the city seriously:

1. **Rules have to be engineered for operations, not just declared.**  
   - Governance has to show up in:
     - workflows,  
     - task boundaries,  
     - logs,  
     - escalation paths –  
     not just in policy docs.

2. **You can’t ignore what the system does to available routes.**  
   - A fully “compliant” system that quietly:
     - erodes meaningful work,  
     - hides whole categories of contribution,  
     - or locks people into dead-end tracks,  
     is still a governance failure.

3. **The two halves interact under stress.**  
   - When value signals move faster than rule systems can adapt:
     - people find informal workarounds,  
     - ignore rules that don’t fit reality,  
     - or disengage.  
   - When rules move faster than shared value and understanding:
     - governance starts to feel imposed and illegitimate.

AI accelerates both sides:

- the pace of decisions and rule-enforcement,  
- the churn in what kinds of work and judgement remain human.

Governance that only stares at “AI systems” and risk categories will miss this.

---

## 5. Legitimacy Under Acceleration: what this project is trying to do

*Legitimacy Under Acceleration* starts from this city picture because it forces two questions at once:

1. **Rule side:**  
   - How do we design governance architectures that:
     - can be wired into real workflows,  
     - can change under pressure without falling apart,  
     - and can be understood and contested by the people they bind?

2. **Value side:**  
   - How do we support new forms of contribution, recognition and meaning:
     - when AI takes over tasks people used to rely on for their identity,  
     - and when old career routes are no longer the centre?

Some of the work I’m doing to explore this:

- a **task boundary framework** – a way of decomposing work so we can say, clearly:
  - what stays human-only,  
  - what becomes AI-assisted,  
  - what can be automated safely,  
  and explain why.
- an **open meta-governance kernel** – rules of rule-change, so that:
  - rules don’t just accrete,  
  - institutions can retire or adapt them as reality shifts,  
  while leaving a legible trail of how and why.
- a **governance–economic lens** – tools for looking at:
  - how rules and value signals interact,  
  - where work and worth are drifting apart,  
  - and where AI is quietly shutting down human routes.

The city metaphor is not decoration. It’s a discipline:

> Every time we talk about “AI governance”,  
> we should be able to point to both a **traffic rule** that changed  
> and a **human route** that stayed open or became possible.

If we can’t do that, we’re not governing AI.  
We’re just adding more signs to a junction that people no longer know how to cross.

That’s the city we’re actually governing. The question is whether we’re willing to see it that way – and build rule systems and value systems that can survive acceleration without losing the people who live in it.
