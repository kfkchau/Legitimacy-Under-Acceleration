## DRAFT - The City Weâ€™re Actually Governing with AI

Most AI governance talk lives in documents:

- principles, risk classes, and impact assessments  
- obligations for providers and deployers  
- audits, evaluations, certifications  

Thatâ€™s the **rule side** of the story.

But if you ask the people living under these systems â€“ workers, professionals, founders, citizens â€“ they donâ€™t experience â€œAI governanceâ€ as a PDF.

They experience:

- which **paths** through work and life are still open  
- which roles still feel meaningful  
- what kinds of effort still â€œcountâ€

Thatâ€™s the **value side**. And AI is rewiring both at once.

This is the city weâ€™re actually governing, whether we admit it or not.

---

## Rules: the traffic system of the city

Start with the familiar half.

One side of the city is built out of **rules** â€“ the traffic system of social life:

- laws and regulations  
- policies and standards  
- procedures, guidance and professional codes  
- the unwritten norms everyone â€œjust knowsâ€

Institutions are the places that host and operate this machinery:

- parliaments, ministries and regulators  
- courts and tribunals  
- companies and boards  
- standards bodies, industry groups, unions  
- universities and professional associations

Together, they form an **ecosystem of governance mechanisms**:

- how rules are made  
- how theyâ€™re interpreted  
- how theyâ€™re enforced  
- how they change (or donâ€™t)  
- how theyâ€™re explained when people push back

This is the part most AI frameworks try to address:

- UNESCO / OECD principles  
- NIST RMF, ISO/IEC 42001  
- the EU AI Act  
- corporate â€œResponsible AIâ€ guidelines  

Theyâ€™re mostly traffic-code work: deciding whatâ€™s allowed at the junction.

Important. Necessary. But not the whole city.

---

## Routes: the value side we almost never talk about

The other side of the city is built out of **value**.

People constantly make judgements about what matters:

- which work deserves respect  
- which products and services are worth paying for  
- which careers feel meaningful  
- which futures feel worth aiming at

In the city, that shows up as the **routes people actually drive**:

- routines and commutes they stick to  
- neighbourhoods that fill up  
- areas they quietly avoid  
- shortcuts, detours, and side-streets that only locals know

Those everyday route choices stand in for **value signals** â€“ all the ways the world tells us what is â€œworth itâ€:

- salaries and prices  
- promotions, titles and bonuses  
- rankings, likes, invitations  
- subtle status and reputation

Markets compress those judgements into numbers.  
The wider economy takes those signals and feeds them back into peopleâ€™s lives:

- what gets funded  
- which jobs are attractive  
- what feels like success or failure  

Most of this never appears in a regulation. But it determines whether people experience a system as **liveable and fair**, or as something theyâ€™re just surviving.

---

## AI is changing both â€“ and our governance only looks at one

Acceleration isnâ€™t just â€œfaster techâ€. Itâ€™s:

- faster **information flow**  
- faster **coordination**  
- faster **feedback loops** â€“ social, economic, political  

AI sits right in the middle of that.

On the **rule side**, weâ€™re adding:

- new principles and codes  
- new obligations and reporting  
- new oversight committees  
- new risk categories for AI systems

On the **value side**, AI is quietly changing:

- which tasks humans still perform  
- which skills are rewarded  
- which roles become structurally fragile

People use their work to answer:

- *What am I actually good at?*  
- *What do people rely on me for?*  
- *What kind of life am I building here?*

When AI moves into the parts of work people were proud of â€“ writing, analysing, diagnosing, coordinating, designing â€“ the **routes** through the city change:

- some career paths thin out or disappear  
- others become overcrowded and precarious  
- new paths appear that arenâ€™t yet recognised or rewarded  

You can end up with a situation where:

- the **traffic system** looks â€œsafe and compliantâ€ on paper  
- but people feel like there are fewer meaningful journeys left for them to make

Thatâ€™s not just a labour-market problem. Itâ€™s a **legitimacy problem**.

---

## Why a rule-only view of AI governance isnâ€™t enough

Most AI governance work today sits almost entirely on the **rule side**:

- defining risk levels and prohibited uses  
- specifying documentation and assessments  
- adding controls and approvals  

All necessary. None of it wrong.

The problem is whatâ€™s *missing*:

1. **No clear view of how rules meet actual workflows**  
   - How is this rule wired into:
     - tasks,  
     - roles,  
     - tools,  
     - logs,  
     - escalation paths?  
   - Can a person under the system explain:
     - *â€œWho decided this, under which rule, and who could have stopped it?â€*

2. **No visibility into what happens to human routes**  
   - As AI rolls out, are there still:
     - meaningful paths for people to grow?  
     - visible ways to contribute and be recognised?  
   - Or are we silently:
     - hollowing out roles,  
     - turning professionals into supervisors of systems they donâ€™t believe in,  
     - pushing valuable work (care, mentoring, glue work) off the metrics?

3. **No language for the interaction between rules and value**  
   - When value signals move faster than rule systems can adapt, people route around rules.  
   - When rules move faster than shared understanding and value, they feel imposed and arbitrary.

If AI governance stays â€œrule-onlyâ€, it will miss where legitimacy is actually leaking.

---

## Thinking in terms of a governanceâ€“economic system

I find it more honest to talk about a **governanceâ€“economic system**:

- **Rule layer**  
  How we structure, constrain and contest decisions:
  - laws, policies, standards, procedures, escalation rules.

- **Value layer**  
  How effort, contribution and risk are recognised and rewarded:
  - pay, status, opportunity, voice.

Under AI acceleration, these two layers are colliding:

- rules are being adapted to fit AI systems  
- AI systems are reshaping which kinds of work and judgement still â€œcountâ€

If you only look at one layer, you get blindsided by the other.

A technically compliant AI rollout that:

- erodes meaningful work,  
- hides whole categories of contribution,  
- or quietly shuts down paths people relied on  

â€¦is still a governance failure, even if every box on the checklist is ticked.

---

## What Legitimacy Under Acceleration is trying to do

Under *Legitimacy Under Acceleration*, Iâ€™m treating this city picture as a design constraint, not just a metaphor.

For me, that means working on both sides at once:

- **On the rule side**  
  Designing governance architectures that:
  - can be wired into real workflows,  
  - can change under pressure without collapsing,  
  - and leave trails people can understand and challenge.

  (Task-boundary work, meta-governance â€œkernelsâ€, governance-first orchestration.)

- **On the value side**  
  Facing the fact that:
  - peopleâ€™s sources of self-worth will have to change,  
  - old career routes wonâ€™t be the centre forever,  
  and asking:
  - how do we support new forms of contribution, recognition and meaning  
    when AI takes over the tasks people once used to answer  
    *â€œwhat am I good for here?â€*

Iâ€™m not claiming to have all the answers. What Iâ€™m trying to do is hold both halves of the city in view when we talk about â€œAI governanceâ€.

Because every time we say that phrase, we should be able to point to:

- a **traffic rule** that changed, *and*  
- a **human route** that stayed open or became possible

If we canâ€™t, then weâ€™re not really governing the system â€“  
weâ€™re just adding more signs to a junction people no longer know how to cross.

---

If this way of looking at AI governance resonates â€“ especially if youâ€™re working on RAIO, architecture, policy, or youâ€™re living through these shifts in your own profession â€“ Iâ€™m building out this work under *Legitimacy Under Acceleration*.

Happy to be in conversation with others who are trying to keep both **rules** and **routes** in view.


---

Â© Kelvin Chau, 2025  
This piece is part of the [Legitimacy Under Acceleration](https://github.com/kfkchau/Legitimacy-Under-Acceleration/) project.  
It may be shared non-commercially with attribution but not modified or republished without permission.  
Licensed under [Creative Commons Attributionâ€“NonCommercialâ€“NoDerivatives 4.0 International (CC BY-NC-ND 4.0)](https://creativecommons.org/licenses/by-nc-nd/4.0/)  
For attribution, citation, or inquiries, please refer to:  
ğŸ”— [https://au.linkedin.com/in/kfkchau](https://au.linkedin.com/in/kfkchau)
