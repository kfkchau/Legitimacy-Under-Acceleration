# DRAFT - THE CITY WEâ€™RE ACTUALLY GOVERNING: Rules, Routes, and the Governanceâ€“Economic System

We talk about AI governance as if itâ€™s mostly about **rules**:  
principles, risk categories, impact assessments, controls, audits.

If youâ€™re living **inside** a system â€“ as a worker, a citizen, a founder, a policymaker â€“ you experience something different:

- not just the rules on paper,  
- but the **routes** that are actually open to you.

Thatâ€™s the gap *Legitimacy Under Acceleration* is interested in:  
not just the laws and frameworks, but the **city** they create.

---

## 1. Two halves of the same city

I work with a simple image: a city being rebuilt while people are still living in it.

### 1.1 The rule side: traffic system and institutions

One half of the city is built out of **rules**.

These are the traffic lights and signposts of social life:

- laws and regulations  
- policies and standards  
- procedures, guidelines and professional codes  
- unwritten norms that everyone â€œjust knowsâ€

Institutions are where these rule systems live and get operated:

- parliaments and ministries  
- regulators and courts  
- companies and boards  
- standards bodies and professional associations  
- universities, unions, industry groups

Together, they form an **ecosystem of governance mechanisms**:

- how rules are made,  
- how theyâ€™re interpreted,  
- how theyâ€™re enforced,  
- how they change,  
- and how theyâ€™re explained when people push back.

This is the part most AI governance frameworks focus on.

### 1.2 The value side: routes, routines, and what â€œcountsâ€

The other half of the city is built out of **value**.

People constantly make judgements about what matters:

- which work deserves respect  
- which products are worth paying for  
- which careers feel meaningful  
- which futures are worth aiming at

In the city, this shows up as the **routes people actually drive**:

- the commutes and routines they stick to  
- the neighbourhoods they crowd  
- the shortcuts and detours they take  
- the areas they quietly avoid

Those everyday route choices stand in for **value signals**:  
all the ways the world tells us what is â€œworth itâ€:

- salaries and prices  
- promotions and titles  
- likes, rankings and invitations  
- informal status and reputation

Markets are where those judgements get **compressed** into numbers:  
prices, wages, KPIs, share prices.

The wider economy is the big **feedback loop** that:

- takes those signals,  
- feeds them back into peopleâ€™s lives,  
- and nudges what feels possible or worthwhile next:
  - what gets funded,  
  - which jobs are attractive,  
  - what counts as success or failure.

Most of this never appears in a law or a framework.  
But it determines whether people experience the system as **liveable**.

---

## 2. The governanceâ€“economic system: rules + routes

Put those halves together and you get what I call the **governanceâ€“economic system**:

- the **rule layer** â€“ how decisions are structured, constrained and contested  
- the **value layer** â€“ how effort, contribution and risk are recognised and rewarded

You canâ€™t really understand one without the other:

- rules that ignore value signals drift into irrelevance or provoke backlash  
- value signals without rule structure drift into exploitation or collapse

Historically, weâ€™ve separated the study of these halves:

- public law, political theory and public administration on the **rule side**  
- economics, finance and management on the **value side**

Under AI acceleration, that split stops being tenable.

AI is reconfiguring **how rules are applied**  
*and* **what kinds of work and contribution â€œcountâ€** at the same time.

---

## 3. How acceleration breaks the alignment

Acceleration isnâ€™t just â€œfaster innovationâ€. Itâ€™s:

- faster **information flow**  
- faster **coordination**  
- faster **feedback loops** â€“ social, economic, political

That hits both halves of the city at once.

### 3.1 On the rule side

We see:

- constant demands for new rules and standards  
- more complex, layered obligations (UNESCO, OECD, NIST, EU, ISO, national law, sectoral codes)  
- institutions struggling to keep up with:
  - new models  
  - new use-cases  
  - new kinds of harm and failure

Most of the global governance stack is still:

- **paper-first** â€“ PDF principles and guidelines  
- **model-centric** â€“ thinking in terms of â€œsystemsâ€ and â€œprovidersâ€, not actual workflows  
- **slow to metabolise** â€“ weak mechanisms for:
  - retiring bad rules,  
  - reconciling contradictions,  
  - reacting coherently to new evidence

So we get traffic lights that change late, or not at all.

### 3.2 On the value side

At the same time, AI and automation are reshaping:

- which tasks humans still do  
- which skills are rewarded  
- which roles are structurally fragile

People use their work to answer questions like:

- â€œWhat am I actually good at?â€  
- â€œWhat do people rely on me for?â€  
- â€œWhat kind of life am I building here?â€

When AI moves into the parts of work people were proud of:

- writing, analysing, diagnosing, designing, coordinating â€“  
the visible **routes** through the city change:

- some career paths thin out or disappear  
- others become overcrowded and precarious  
- new paths emerge that arenâ€™t yet recognised or rewarded

The risk is simple:

> Even if the traffic system is â€œsafe and compliantâ€,  
> people can feel like there are fewer meaningful journeys left for them to make.

Thatâ€™s how legitimacy leaks out.

---

## 4. Why AI governance canâ€™t stay rule-only

Most current AI governance efforts sit almost entirely on the **rule side**:

- principles, obligations, risk classes  
- impact assessments and audits  
- definitions of high-risk vs low-risk systems

Thatâ€™s necessary. Itâ€™s not sufficient.

Three things follow if you take the city seriously:

1. **Rules have to be engineered for operations, not just declared.**  
   - Governance has to show up in:
     - workflows,  
     - task boundaries,  
     - logs,  
     - escalation paths â€“  
     not just in policy docs.

2. **You canâ€™t ignore what the system does to available routes.**  
   - A fully â€œcompliantâ€ system that quietly:
     - erodes meaningful work,  
     - hides whole categories of contribution,  
     - or locks people into dead-end tracks,  
     is still a governance failure.

3. **The two halves interact under stress.**  
   - When value signals move faster than rule systems can adapt:
     - people find informal workarounds,  
     - ignore rules that donâ€™t fit reality,  
     - or disengage.  
   - When rules move faster than shared value and understanding:
     - governance starts to feel imposed and illegitimate.

AI accelerates both sides:

- the pace of decisions and rule-enforcement,  
- the churn in what kinds of work and judgement remain human.

Governance that only stares at â€œAI systemsâ€ and risk categories will miss this.

---

## 5. Legitimacy Under Acceleration: what this project is trying to do

*Legitimacy Under Acceleration* starts from this city picture because it forces two questions at once:

1. **Rule side:**  
   - How do we design governance architectures that:
     - can be wired into real workflows,  
     - can change under pressure without falling apart,  
     - and can be understood and contested by the people they bind?

2. **Value side:**  
   - How do we support new forms of contribution, recognition and meaning:
     - when AI takes over tasks people used to rely on for their identity,  
     - and when old career routes are no longer the centre?

Some of the work Iâ€™m doing to explore this:

- a **task boundary framework** â€“ a way of decomposing work so we can say, clearly:
  - what stays human-only,  
  - what becomes AI-assisted,  
  - what can be automated safely,  
  and explain why.
- an **open meta-governance kernel** â€“ rules of rule-change, so that:
  - rules donâ€™t just accrete,  
  - institutions can retire or adapt them as reality shifts,  
  while leaving a legible trail of how and why.
- a **governanceâ€“economic lens** â€“ tools for looking at:
  - how rules and value signals interact,  
  - where work and worth are drifting apart,  
  - and where AI is quietly shutting down human routes.

The city metaphor is not decoration. Itâ€™s a discipline:

> Every time we talk about â€œAI governanceâ€,  
> we should be able to point to both a **traffic rule** that changed  
> and a **human route** that stayed open or became possible.

If we canâ€™t do that, weâ€™re not governing AI.  
Weâ€™re just adding more signs to a junction that people no longer know how to cross.

Thatâ€™s the city weâ€™re actually governing. The question is whether weâ€™re willing to see it that way â€“ and build rule systems and value systems that can survive acceleration without losing the people who live in it.

---

Â© Kelvin Chau, 2025  
This piece is part of the [Legitimacy Under Acceleration](https://github.com/kfkchau/Legitimacy-Under-Acceleration/) project.  
It may be shared non-commercially with attribution but not modified or republished without permission.  
Licensed under [Creative Commons Attributionâ€“NonCommercialâ€“NoDerivatives 4.0 International (CC BY-NC-ND 4.0)](https://creativecommons.org/licenses/by-nc-nd/4.0/)  
For attribution, citation, or inquiries, please refer to:  
ðŸ”— [https://au.linkedin.com/in/kfkchau](https://au.linkedin.com/in/kfkchau)
